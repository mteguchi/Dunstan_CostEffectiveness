---
title: "Hatchling counts at Raine Island"
author: "Tomo Eguchi"
date: "`r Sys.Date()`"
output: 
  bookdown::word_document2: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# # remove all pakcages - detach() removes the first one.
# loaded.packages <- (.packages())
# if (length(loaded.packages > 0)){
#   for (k in 1:length(loaded.packages)){
#     detach()
#   }
# }

rm(list = ls())
library(tidyverse)
library(readr)
library(flextable)
library(cowplot)
library(lubridate)
library(loo)

source("Dunstan_functions.R")



set_flextable_defaults(font.size = 9,
                       font.family = "Cambria")



save.fig <- T
dpi.set <- 600

```

## Background {-}

At Raine Island, annual hatchling production has been determined via counts of hatchlings on the beach. Observers are stationed at multiple sectors, where they count hatchlings that come down the beach. A trench is dug and all hatchlings that fall into the trench are counted and released hourly. During the 2018-2019 season, the survey was changed from 12 hrs (1800 to 0600) to 6 hrs (1800 - 0000) for logistical reasons. 

In order to look at possible effects of differences in sampling scheme (i.e., 12hr vs 6 hr), I compare hatchling count data between the two sampling design. I converted the counts to counts per meter using the length of a trench (50 m vs 100 m). All analyses were conducted on the number of observed hatchlings per meter per hour. Furthermore, in order to consider the differences in the number of nesting females per nesting season, I divided the number of hatchlings per meter per hour by the estimated number of females (Petersen estimates from vessel-based survey) divided by 1000. The unit of the variable of interest, therefore, is the number of hatchlings per meter per hour per 1000 females. 

```{r data-import, include=FALSE, echo=FALSE, message=FALSE, warning=FALSE}

col.def <- cols(date = col_date(format = "%d/%m/%Y"),
                sector = col_factor(levels = c("A", "A2", "B", "D", "2014S", "2017S", "2019S", "2019N")),
                island = col_character(),
                trench_length_m = col_double(), 
                survey_length = col_character(), 
                total_before_1800 = col_integer(), 
                total_1800_1900 = col_integer(), 
                total_1900_2000 = col_integer(), 
                total_2000_2100 = col_integer(),
                total_2100_2200 = col_integer(),
                total_2200_2300 = col_integer(),
                total_2300_2400 = col_integer(),
                total_2400_0100 = col_integer(),
                total_0100_0200 = col_integer(), 
                total_0200_0300 = col_integer(),
                total_0300_0400 = col_integer(),
                total_0400_0500 = col_integer(),
                total_0500_0600 = col_integer(),
                total_after_0600 = col_integer(),
                nightly_total = col_integer())

data.0 <- read_csv(file = "data/hatch_count_fullcount_2014-15-2021-22.csv",
                   col_types = col.def) %>% 
  discard(~ all(is.na(.))) %>%
  mutate(survey_duration_hr = ifelse(survey_length == "12hr", 12, 6)) %>%
  mutate(year = lubridate::year(date),
         month = lubridate::month(date),
         date_num = as.numeric(date)) 


data.0 %>%
  select(-c("survey_length", "nightly_total")) %>%
  pivot_longer(data.0,
               cols = starts_with("total"),
               names_to = "time",
               values_to = "counts") %>%
  mutate(hr = ifelse(time == "total_before_1800", 0,
                     ifelse(time == "total_1800_1900", 1,
                            ifelse(time == "total_1900_2000", 2,
                                   ifelse(time == "total_2000_2100", 3,
                                          ifelse(time == "total_2100_2200", 4,
                                                 ifelse(time == "total_2200_2300", 5,
                                                        ifelse(time == "total_2300_2400", 6,
                                                               ifelse(time == "total_2400_0100", 7,
                                                                      ifelse(time == "total_0100_0200", 8,
                                                                             ifelse(time == "total_0200_0300", 9,
                                                                                    ifelse(time == "total_0300_0400", 10,
                                                                                           ifelse(time == "total_0400_0500", 11,
                                                                                                  ifelse(time == "total_0500_0600", 12, 13)))))))))))))) %>%
  mutate(counts_m = counts/trench_length_m) %>%
  mutate(counts_m_NA = ifelse((survey_duration_hr == 6 & hr > 6), NA, counts_m)) -> data.1


# Ballpark figures of nesting female abundance - extracted from Figure 2 of Raine Island Recovery Project 2021-22 Technical report.pdf. - To be updated with more precise numbers. 

n.females.df <- data.frame(year = c(2015:2022),
                           n.females = scale(c(15000, 5000, 12000, 20000, 1000, 38000, 1000, 12000)))

# combine the # females into the data
data.1 %>% left_join(n.females.df, by = "year") %>%
  mutate(counts_m_NA_female = 1000 * counts_m_NA/n.females) -> data.1

p.females <- ggplot(n.females.df) +
  geom_point(aes(x = year, y = n.females/1000), size = 2) +
  xlab("") + ylab("Estimated number of females (1000s)")

save.fig.fcn(p.females, 
             file.name = paste0("figures/females_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)

```




```{r pivot-check, message=FALSE, echo=FALSE, warning=FALSE}
# Make sure the pivoting worked correctly:

data.0 %>% 
  filter(year == 2020, sector == "A") %>%
  mutate(date.f = as.factor(date)) %>%
  group_by(date.f) %>%
  rowwise() %>%
  mutate(daily.sum = sum(c_across(starts_with("total")))) -> data.0.A.2020.daily.sum


data.1 %>% 
  filter(year == 2020, sector == "A") %>%
  mutate(date.f = as.factor(date)) %>%
  group_by(date.f) %>%
  summarize(daily.sum = sum(counts, na.rm = T)) -> data.1.A.2020.daily.sum


data.0 %>% 
  filter(year == 2015, sector == "2014S") %>%
  mutate(date.f = as.factor(date)) %>%
  group_by(date.f) %>%
  rowwise() %>%
  mutate(daily.sum = sum(c_across(starts_with("total")), na.rm = T)) -> data.0.2014S.2015.daily.sum


data.1 %>% 
  filter(year == 2015, sector == "2014S") %>%
  mutate(date.f = as.factor(date)) %>%
  group_by(date.f) %>%
  summarize(daily.sum = sum(counts, na.rm = T)) -> data.1.2014S.2015.daily.sum

# Two sets are the same so I assume that the pivoting operations worked fine to convert the wide format to long format.

```

In general, greater numbers of hatchlings were counted before midnight (6hrs since 1800) than after. The observed number of hatchlings ranged from `r signif(min(data.1$counts_m_NA, na.rm=T), 2)` to `r signif(max(data.1$counts_m_NA, na.rm=T), 2)` per meter per hour. When these numbers were standardized for the estimated number of adult females (in 1000s; Figure \@ref(fig:Figure-females)), they ranged from `r signif(min(data.1$counts_m_NA_female, na.rm=T), 2)` to `r signif(max(data.1$counts_m_NA_female, na.rm=T), 2)` per meter per hour per 1000 adult females (Figure \@ref(fig:Figure-raw-counts)).


```{r Figure-females, echo=FALSE, message=FALSE, fig.cap="The estimated number of females per year from vessel-based Petersen estimates"}

knitr::include_graphics(paste0("figures/females_", dpi.set, "dpi.png"))

```

In order to look at the details, each sector was examined separately. 

```{r raw-plot, echo=FALSE, message=FALSE, warning=FALSE}
p.raw.counts <- ggplot(data = data.1) +
  # geom_point(aes(x = hr, 
  #                y = counts, 
  #                color = sector)) +
  geom_path(aes(x = hr, 
                 y = counts_m_NA, 
                 color = as.factor(year))) +
  facet_wrap(~sector, nrow = 2) +
  labs(color = "Year") +
  theme(legend.position = "none") +
  xlab("Hours since 1800") + ylab("# hatchlings per meter")


p.raw.counts.per.female <- ggplot(data = data.1) +
  # geom_point(aes(x = hr, 
  #                y = counts, 
  #                color = sector)) +
  geom_path(aes(x = hr, 
                 y = counts_m_NA_female, 
                 color = as.factor(year))) +
  facet_wrap(~sector, nrow = 2) +
  labs(color = "Year") +
  xlab("Hours since 1800") + ylab("# hatchlings per meter per 1000 females")

p.counts <- plot_grid(p.raw.counts, p.raw.counts.per.female,
                      labels = c("(1)", "(2)"))

save.fig.fcn(p.counts, 
             file.name = paste0("figures/raw_counts_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)

```


```{r Figure-raw-counts, echo=FALSE, message=FALSE, fig.cap="The number of hatchlings per meter at 8 sectors."}

knitr::include_graphics(paste0("figures/raw_counts_", dpi.set, "dpi.png"))

```

## Sector-specific pattern {-}

### Sector A {-}

```{r sector-A, echo=FALSE, message=FALSE, warning=FALSE}
xlab.txt <- "Hours since 1800"
ylab.1.txt <- "# hatchlings per meter"
ylab.2.txt <- "# hatchlings per meter per 1000 females"

data.1 %>% filter(sector == "A") -> data.1.A

p.sector.A <- ggplot(data.1.A) +
  geom_path(aes(x = hr, y = counts_m_NA)) +
  facet_wrap(~year) + 
  xlab(xlab.txt) +
  ylab(ylab.1.txt)

p.sector.A.female <- ggplot(data.1.A) +
  geom_path(aes(x = hr, y = counts_m_NA_female)) +
  facet_wrap(~year) + 
  xlab(xlab.txt) +
  ylab(ylab.2.txt)

p.sector.A.1 <- plot_grid(p.sector.A, p.sector.A.female,
                          labels = c("(1)", "(2)"))

save.fig.fcn(p.sector.A.1, 
             file.name = paste0("figures/sector_A_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)

```

At sector A, only 6-hr surveys were conducted in `r min(data.1.A$year)` - `r max(data.1.A$year)`. The observed variability among surveys in 2020 was large (Figure \@ref(fig:Figure-sector-A)). In 2021, even though the number of hatchlings was low, the number of hatchligs per 1000 females was higher than the other two years (Figure \@ref(fig:Figure-sector-A)), indicating a negative relationship between hatching success rates and the number of females. 


```{r Figure-sector-A, echo=FALSE, message=FALSE, fig.cap="The number of hatchlings per meter (1) and the number of hatchlings per meter per 1000 females (2) at sector A."}

knitr::include_graphics(paste0("figures/sector_A_", dpi.set, "dpi.png"))

```


### Sector A2 {-}

```{r sector-A2, echo=FALSE, message=FALSE, warning=FALSE}

data.1 %>% filter(sector == "A2") -> data.1.A2

p.sector.A2 <- ggplot(data.1.A2) +
  geom_path(aes(x = hr, y = counts_m_NA)) +
  facet_wrap(~year)+ 
  xlab(xlab.txt) +
  ylab(ylab.1.txt) +
  theme(legend.position = "none")

p.sector.A2.female <- ggplot(data.1.A2) +
  geom_path(aes(x = hr, y = counts_m_NA_female)) +
  facet_wrap(~year)+ 
  xlab(xlab.txt) +
  ylab(ylab.2.txt)

p.sector.A2.1 <- plot_grid(p.sector.A2, p.sector.A2.female,
                          labels = c("(1)", "(2)"))

save.fig.fcn(p.sector.A2.1, 
             file.name = paste0("figures/sector_A2_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)

```

In sector A2, 12-hr surveys were conducted from 2015 to 2018, whereas 6-hr surveys were conducted in 2019. 12-hr surveys indicated that hourly counts of hatchlings reached greatest in the first 6 hrs, especially 3-4 hrs from the beginning of each survey (2100-2200) and declined subsequently (Figure \@ref(fig:Figure-sector-A2)).


```{r Figure-sector-A2, echo=FALSE, message=FALSE, fig.cap="The number of hatchlings per meter (1) and the number of hatchlings per meter per 1000 females (2) at sector A2."}

knitr::include_graphics(paste0("figures/sector_A2_", dpi.set, "dpi.png"))

```

### Sector B {-}

```{r sector-B, echo=FALSE, message=FALSE, warning=FALSE}

data.1 %>% filter(sector == "B") -> data.1.B

p.sector.B <- ggplot(data.1.B) +
  geom_path(aes(x = hr, y = counts_m_NA)) +
  facet_wrap(~year)+ 
  xlab(xlab.txt) +
  ylab(ylab.1.txt) 

p.sector.B.female <- ggplot(data.1.B) +
  geom_path(aes(x = hr, y = counts_m_NA_female)) +
  facet_wrap(~year)+ 
  xlab(xlab.txt) +
  ylab(ylab.2.txt) 

p.sector.B.1 <- plot_grid(p.sector.B, p.sector.B.female,
                          labels = c("(1)", "(2)"))

save.fig.fcn(p.sector.B.1, 
             file.name = paste0("figures/sector_B_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)

```


In sector B, 12-hr surveys were conducted from 2015 to 2018, whereas 6-hr surveys were conducted from 2019 to 2022. 12-hr surveys in 2016 and 2018 indicated that hourly counts of hatchlings reached greatest in the first 6 hrs, especially 3-4 hrs from the beginning of each survey (2100-2200) and declined subsequently (Figure \@ref(fig:Figure-sector-B)). In other years (e.g., 2015 and 2017), no obvious peaks were observed, although the counts were higher during the first half of survey than the latter half. 


```{r Figure-sector-B, echo=FALSE, message=FALSE, fig.cap="The number of hatchlings per meter (1) and the number of hatchlings per meter per 1000 females (2) at sector B."}

knitr::include_graphics(paste0("figures/sector_B_", dpi.set, "dpi.png"))

```


### Sector D {-}

```{r sector-D, echo=FALSE, message=FALSE, warning=FALSE}

data.1 %>% filter(sector == "D") -> data.1.D

p.sector.D <- ggplot(data.1.D) +
  geom_path(aes(x = hr, y = counts_m_NA)) +
  facet_wrap(~year)+ 
  xlab(xlab.txt) +
  ylab(ylab.1.txt)


p.sector.D.female <- ggplot(data.1.D) +
  geom_path(aes(x = hr, y = counts_m_NA_female)) +
  facet_wrap(~year)+ 
  xlab(xlab.txt) +
  ylab(ylab.1.txt)

p.sector.D.1 <- plot_grid(p.sector.D, p.sector.D.female,
                          labels = c("(1)", "(2)"))

save.fig.fcn(p.sector.D.1, 
             file.name = paste0("figures/sector_D_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)

```


In sector D, 12-hr surveys were conducted in 2017 and 2018, whereas 6-hr surveys were conducted in 2016, 2019, and 2020. A 12-hr survey in 2017 indicated that hourly counts of hatchlings were greatest in the second hour of the survey (2000) and declined subsequently (Figure \@ref(fig:Figure-sector-D)). In 2018, a peak was observed at the 6th hour (2400). 


```{r Figure-sector-D, echo=FALSE, message=FALSE, fig.cap="The number of hatchlings per meter (1) and the number of hatchlings per meter per 1000 females (2) at sector D."}

knitr::include_graphics(paste0("figures/sector_D_", dpi.set, "dpi.png"))

```

### Sector 2014S {-}

```{r sector-2014S, echo=FALSE, message=FALSE, warning=FALSE}

data.1 %>% filter(sector == "2014S") -> data.1.2014S

p.sector.2014S <- ggplot(data.1.2014S) +
  geom_path(aes(x = hr, y = counts_m_NA)) +
  facet_wrap(~year)+ 
  xlab(xlab.txt) +
  ylab(ylab.1.txt)

p.sector.2014S.female <- ggplot(data.1.2014S) +
  geom_path(aes(x = hr, y = counts_m_NA_female)) +
  facet_wrap(~year)+ 
  xlab(xlab.txt) +
  ylab(ylab.2.txt)

p.sector.2014S.1 <- plot_grid(p.sector.2014S, p.sector.2014S.female,
                          labels = c("(1)", "(2)"))

save.fig.fcn(p.sector.2014S.1, 
             file.name = paste0("figures/sector_2014S_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)
```


In sector 2014S, 12-hr surveys were conducted from 2015 to 2018, whereas 6-hr surveys were conducted from 2019 to 2022 (Figure \@ref(fig:Figure-sector-2014S)). Higher counts were recorded in the first half (1800-2400) of the night.  


```{r Figure-sector-2014S, echo=FALSE, message=FALSE, fig.cap="The number of hatchlings per meter (1) and the number of hatchlings per meter per 1000 females (2) at sector 2014S."}

knitr::include_graphics(paste0("figures/sector_2014S_", dpi.set, "dpi.png"))

```

### Sector 2017S {-}
```{r sector-2017S, echo=FALSE, message=FALSE, warning=FALSE}

data.1 %>% filter(sector == "2017S") -> data.1.2017S

p.sector.2017S <- ggplot(data.1.2017S) +
  geom_path(aes(x = hr, y = counts_m_NA)) +
  facet_wrap(~year)+ 
  xlab(xlab.txt) +
  ylab(ylab.1.txt)

p.sector.2017S.female <- ggplot(data.1.2017S) +
  geom_path(aes(x = hr, y = counts_m_NA_female)) +
  facet_wrap(~year)+ 
  xlab(xlab.txt) +
  ylab(ylab.2.txt)

p.sector.2017S.1 <- plot_grid(p.sector.2017S, p.sector.2017S.female,
                          labels = c("(1)", "(2)"))

save.fig.fcn(p.sector.2017S.1, 
             file.name = paste0("figures/sector_2017S_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)
```

In sector 2017S, 12-hr surveys were conducted in 2018, whereas 6-hr surveys were conducted from 2019 to 2021 (Figure \@ref(fig:Figure-sector-2017S)). Counts from 2018 indicated that the number of hatchlings was greater before the midnight than after. No apparent peaks were found for 2019, 2020, or 2021.  


```{r Figure-sector-2017S, echo=FALSE, message=FALSE, fig.cap="The number of hatchlings per meter (1) and the number of hatchlings per meter per 1000 females (2) at sector 2017S."}

knitr::include_graphics(paste0("figures/sector_2017S_", dpi.set, "dpi.png"))

```

### Sector 2019S {-}
```{r sector-2019S, echo=FALSE, message=FALSE, warning=FALSE}

data.1 %>% filter(sector == "2019S") -> data.1.2019S

p.sector.2019S <- ggplot(data.1.2019S) +
  geom_path(aes(x = hr, y = counts_m_NA)) +
  facet_wrap(~year)+ 
  xlab(xlab.txt) +
  ylab(ylab.1.txt)

p.sector.2019S.female <- ggplot(data.1.2019S) +
  geom_path(aes(x = hr, y = counts_m_NA_female)) +
  facet_wrap(~year)+ 
  xlab(xlab.txt) +
  ylab(ylab.2.txt)

p.sector.2019S.1 <- plot_grid(p.sector.2019S, p.sector.2019S.female,
                          labels = c("(1)", "(2)"))

save.fig.fcn(p.sector.2019S.1, 
             file.name = paste0("figures/sector_2019S_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)
```

In Sector 2019S, only 6-hr surveys were conducted. An apparent peak at 2 hrs after 1800 (2000) was observed for 2022, whereas the timing of the peak for 2020 was inconclusive between the two surveys. No apparent peak was observed for 2021 (Figure \@ref(fig:Figure-sector-2019S)). 

```{r Figure-sector-2019S, echo=FALSE, message=FALSE, fig.cap="The number of hatchlings per meter (1) and the number of hatchlings per meter per 1000 females (2) at sector 2019S."}

knitr::include_graphics(paste0("figures/sector_2019S_", dpi.set, "dpi.png"))

```

### Sector 2019N {-}
```{r sector_2019N, echo=FALSE, message=FALSE, warning=FALSE}

data.1 %>% filter(sector == "2019N") -> data.1.2019N

p.sector.2019N <- ggplot(data.1.2019N) +
  geom_path(aes(x = hr, y = counts_m_NA)) +
  facet_wrap(~year)+ 
  xlab(xlab.txt) +
  ylab(ylab.1.txt)

p.sector.2019N.female <- ggplot(data.1.2019N) +
  geom_path(aes(x = hr, y = counts_m_NA_female)) +
  facet_wrap(~year)+ 
  xlab(xlab.txt) +
  ylab(ylab.2.txt)

p.sector.2019N.1 <- plot_grid(p.sector.2019N, p.sector.2019N.female,
                          labels = c("(1)", "(2)"))

save.fig.fcn(p.sector.2019N.1, 
             file.name = paste0("figures/sector_2019N_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)
```

In sector 2019N, a peak was observed at 2-3 hrs after 1800 (2000-2100) in 2022 (Figure \@ref(fig:Figure-sector-2019N)).

```{r Figure-sector-2019N, echo=FALSE, message=FALSE, fig.cap="The number of hatchlings per meter (1) and the number of hatchlings per meter per 1000 females (2) at sector 2019N."}

knitr::include_graphics(paste0("figures/sector_2019N_", dpi.set, "dpi.png"))

```

## Estimating counts for 12-hr from 6-hr sampling {-}

It appears that more hatchlings are generally found before midnight. An objective of this project is to estimate the total number of hatchlings per night (1800 - 0600) from a reduced sampling design that counted the number of hatchlings in 6-hr period (1800 - 2400). Two approaches were used to estimate the total counts from partial counts: (1) using the ratios between the first and second half and (2) develop a regression model to determine the relationship between the first and second halves.

### Ratios between the two sampling periods (1800-0600 vs. 1800-2400)

```{r first-vs-second, echo=FALSE, message=FALSE, warning=FALSE}

counts.1st.2nd <- calculate.ratio(data.1)

p.ratio.sector <- ggplot(data = counts.1st.2nd) +
  geom_point(aes(x = date, y = ratio)) +
  facet_wrap(~sector)


save.fig.fcn(p.ratio.sector, 
             file.name = paste0("figures/ratio_sector_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)

```

The proportion of hatchlings that were counted during the first 6 hrs, i.e., 1800 to 2400, relative to the 12-hr period (1800-0600) ranged from `r signif(min(counts.1st.2nd$ratio), 3)` to `r signif(max(counts.1st.2nd$ratio), 3)`. Majority of them were greater than 0.5 (`r counts.1st.2nd %>% filter(ratio > 0.5) %>% nrow()` of `r nrow(counts.1st.2nd)`), mean = `r signif(mean(counts.1st.2nd$ratio), 3)`, SE = `r signif(sqrt(var(counts.1st.2nd$ratio))/sqrt(nrow(counts.1st.2nd)), 3)`). Two counts that resulted in low proportions of hatchlings during the first half of the evenings occurred in 2018 in sector A2 (Figure \@ref(fig:)).


```{r Figure-ratio-sectors, echo=FALSE, message=FALSE, fig.cap="The proportion of hatchlings per meter during the first half of the evening (1800-2400) in the total number of hatchlings (1800-0600)."}

knitr::include_graphics(paste0("figures/ratio_sector_", dpi.set, "dpi.png"))

```

```{r sector-year-summary, echo=FALSE, message=FALSE}

# counts.1st.2nd %>%
#   group_by(sector, year) %>%
#   summarise(var = var(ratio),
#             mean = mean(ratio)) -> year.sector.var.mean
# 

counts.1st.2nd %>%
  group_by(year,sector) %>%
  summarize(mean.ratio = mean(ratio),
            SE.ratio = sqrt(var(ratio))/sqrt(n()),
            n = n()) -> counts.1st.2nd.means

counts.1st.2nd %>%
  group_by(year) %>%
  summarise(mean.sectors = mean(ratio),
            SE.sectors = sqrt(var(ratio))/sqrt(n())) -> counts.1st.2nd.sectors

counts.1st.2nd %>%
  group_by(sector) %>%
  summarise(mean.years = mean(ratio),
            SE.years = sqrt(var(ratio))/sqrt(n())) -> counts.1st.2nd.years


```

```{r}
p.ratio.year <- ggplot(data = counts.1st.2nd) +
  geom_point(aes(x = sector, y = ratio)) +
  facet_wrap(~year)

save.fig.fcn(p.ratio.year, 
             file.name = paste0("figures/ratio_year_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)

```

These plots show that variability in the ratio is smaller among sectors within a year than among years within each sector, except 2018 in sector A2 (Figure \@ref(fig:Figure-ratio-years)). Standard errors within year ranged from `r signif(min(counts.1st.2nd.sectors$SE.sectors), 3)` to `r signif(max(counts.1st.2nd.sectors$SE.sectors), 3)`, whereas those within sector ranged from `r signif(min(counts.1st.2nd.years$SE.years), 3)` to `r signif(max(counts.1st.2nd.years$SE.years), 3)`.


```{r Figure-ratio-years, echo=FALSE, message=FALSE, fig.cap="The proportion of hatchlings per meter during the first half of the evening (1800-2400) in the total number of hatchlings (1800-0600) within each sector."}

knitr::include_graphics(paste0("figures/ratio_year_", dpi.set, "dpi.png"))

```

Cross validations were conducted for all date- and sector-specific surveys that were 12 hr long. The second half of each survey was computed using the first half of the survey and the proportion of the first half that was computed using either (1) only the same sector for that year, (2) all sectors for that year, (3) all other sectors for that year, or (4) all sectors from other years. 

```{r cross-validation-1, echo=FALSE, message=FALSE, warning=FALSE}
compute.2nd <- function(m.1st, mean.ratio){
  m.2nd <- ((1/mean.ratio) - 1) * m.1st 
}

# Only 12-hr surveys are used in this exercise:
data.1 %>% filter(survey_duration_hr > 6) -> data.1.12hr
counts.1st.2nd.12hr <- calculate.ratio(data.1.12hr)

# Create a sequential ID number for each survey 
date_num_df <- data.frame(date_num = unique(data.1.12hr$date_num),
                          date_seq = 1:length(unique(data.1.12hr$date_num)))

data.1.12hr %>%
  left_join(date_num_df, by = "date_num") -> data.1.12hr

data.out <- counts.1st.2nd.12hr
data.out$estim.1 <-  NA
data.out$estim.all <- NA
data.out$estim.others <- NA
data.out$estim.other.yrs <- NA

# first, I use all surveys except one. 
n.surveys <- length(unique(data.1.12hr$date_seq))

k <- 1
for (k in 1:n.surveys){
  data.1.k <- data.1.12hr %>% filter(date_seq == k)
  counts.1st.2nd.k <- calculate.ratio(data.1.k)
  
  year.k <- counts.1st.2nd.k$year[1]
  date.k <- counts.1st.2nd.k$date[1]
  
  data.1.1 <- data.1.12hr %>% filter(date_seq != k, year == year.k)
  counts.1st.2nd.1 <- calculate.ratio(data.1.1)
  
  # data from other years
  data.1.other.years  <- data.1.12hr %>% filter(year != year.k)
  counts.1st.2nd.other.years <- calculate.ratio(data.1.other.years)
  mean.other.years <- mean(counts.1st.2nd.other.years$ratio)

  # use the same sector or use all or all other:
  k1 <- 2
  for (k1 in 1:nrow(counts.1st.2nd.k)){
    
    sector.1 <- counts.1st.2nd.k$sector[k1] %>% as.character()
    m.1st <- counts.1st.2nd.k$counts_m_1[k1]
    
    # same sector:
    counts.1st.2nd.1 %>%
      filter( sector == sector.1) -> ratio.1.sector
    
    # other sectors
    counts.1st.2nd.1 %>%
      filter(sector != sector.1) -> ratio.other.sectors
      
    mean.1.sector <- mean(ratio.1.sector$ratio)
    mean.all.sectors <- mean(counts.1st.2nd.1$ratio)
    mean.other.sectors <- mean(ratio.other.sectors$ratio)
    
    data.out[data.out$sector == sector.1 & 
               data.out$date == date.k, "estim.1"] <- compute.2nd(m.1st, mean.1.sector)
    data.out[data.out$sector == sector.1 & 
               data.out$date == date.k, "estim.all"] <- compute.2nd(m.1st, mean.all.sectors)
    data.out[data.out$sector == sector.1 & 
               data.out$date == date.k, "estim.others"] <- compute.2nd(m.1st, mean.other.sectors)
    data.out[data.out$sector == sector.1 & 
               data.out$date == date.k, "estim.other.yrs"] <- compute.2nd(m.1st, mean.other.years)
  }

}

data.out %>%
  mutate(dif.1 = estim.1 - counts_m_2,
         dif.all = estim.all - counts_m_2,
         dif.others = estim.others - counts_m_2,
         dif.other.yrs = estim.other.yrs - counts_m_2,
         year.seq = year - 2015 + 1,
         year.seq.f = as.factor(year.seq)) -> data.out

p.estimates.1 <- ggplot(data = data.out) +
  geom_point(aes(x = counts_m_2, y = estim.1, color = sector)) +
  geom_abline(slope = 1, intercept = 0)+
  xlab("") + ylab("Calculated counts per m")+
  theme(axis.title = element_text(size = 10)) +
  facet_wrap(~ year)

p.estimates.all <- ggplot(data = data.out) +
  geom_point(aes(x = counts_m_2, y = estim.all, color = sector)) +
  geom_abline(slope = 1, intercept = 0)+
  xlab("") + ylab("")+
  #theme(axis.title = element_text(size = 10)) +
  facet_wrap(~ year)

p.estimates.other.years <- ggplot(data = data.out) +
  geom_point(aes(x = counts_m_2, y = estim.other.yrs, color = sector)) +
  geom_abline(slope = 1, intercept = 0)+
  xlab("Observed counts per m") + ylab("Calculated counts per m")+
  theme(axis.title = element_text(size = 10)) +
  facet_wrap(~ year)

p.estimates.others <- ggplot(data = data.out) +
  geom_point(aes(x = counts_m_2, y = estim.others, color = sector)) +
  geom_abline(slope = 1, intercept = 0)+
  xlab("Observed counts per m") + ylab("")+
  theme(axis.title = element_text(size = 10)) +
  facet_wrap(~ year)


p.estimates <- plot_grid(p.estimates.1 + theme(legend.position = "none"), 
                         p.estimates.all + theme(legend.position = "none"), 
                         p.estimates.other.years + theme(legend.position = "none"), 
                         p.estimates.others + theme(legend.position = "none"),
                         labels = c("A", "B", "C", "D"),
                         nrow = 2)

legend <- get_legend(p.estimates.1 + guides(color = guide_legend(nrow = 1)) +
                       theme(legend.position = "bottom"))

p.estimates.grid <- plot_grid(p.estimates, legend, ncol = 1,
                              rel_heights = c(1, 0.1))

save.fig.fcn(p.estimates.grid, 
             file.name = paste0("figures/ratio_counts_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)

p.difs.1 <- ggplot(data = data.out) +
  geom_jitter(aes(x = sector, 
                  y = dif.1), 
              color = "orange", size = 2,
              width = 0.2, height = 0) +
  geom_jitter(aes(x = sector, y = dif.all), 
              color = "purple", size = 2,
              width = 0.2, height = 0) +
  geom_jitter(aes(x = sector, y = dif.others), 
              color = "red", size = 2,
              width = 0.2, height = 0) +
  geom_jitter(aes(x = sector, y = dif.other.yrs), 
              color = "yellow", size = 2,
              width = 0.2, height = 0) +
  facet_wrap(~ year)

save.fig.fcn(p.difs.1, 
             file.name = paste0("figures/ratio_difs_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)

ratio.summary.table <- data.frame(Sets = c("One sector", "All sectors", 
                                           "Other sectors", "Other years"),
                                  Mean = c(mean(data.out$dif.1, na.rm = T),
                                           mean(data.out$dif.all),
                                           mean(data.out$dif.others),
                                           mean(data.out$dif.other.yrs)),
                                  SD = c(sqrt(var(data.out$dif.1, na.rm = T)),
                                         sqrt(var(data.out$dif.all)),
                                         sqrt(var(data.out$dif.others)),
                                         sqrt(var(data.out$dif.other.yrs))),
                                  min = c(min(data.out$dif.1, na.rm = T), 
                                          min(data.out$dif.all),
                                           min(data.out$dif.others), 
                                          min(data.out$dif.other.yrs)),
                                  max = c(max(data.out$dif.1, na.rm = T),
                                          max(data.out$dif.all),
                                           max(data.out$dif.others),
                                          max(data.out$dif.other.yrs)))

```


```{r Figure-X-validation, echo=FALSE, message=FALSE, fig.cap = "Observed and calculated numbers of hatchlings using the ratio between the first and total number of hatchlings. Calculations were conducted in a cross validation manner where each survey was withheld from computing the ratio to be used in calculating the second half of the evening. A: Using the same sector within the same year, B: Using all sectors within the same year, C: Using other sectors within the same year, and D: Using all sectors from other years. The solid lines indicate the correct answer." }

knitr::include_graphics(paste0("figures/ratio_counts_", dpi.set, "dpi.png"))
```



```{r Figure-ratio, echo=FALSE, message=FALSE, fig.cap="The differences between the observed and calculated numbers of hatchlings using the ratio between the first and total number of hatchlings. Calculations were conducted in a cross validation manner where each survey was withheld from computing the ratio to be used in calculating the second half of the evening. Colors indicate different sets of data to cross validate: orange = using the same sector within the same year, purple = using all sectors within the same year, red = using other sectors witin the same year, and yellow = using all sectors from other years."}

knitr::include_graphics(paste0("figures/ratio_difs_", dpi.set, "dpi.png"))

```


The comparison of the calculated values (i.e., hatchling counts during the second half of each survey) indicated that the using all sectors from all other years resulted in smallest variability in the difference between the true and calculated values, followed by using all sectors within the same year (Table \@ref(tab:Table-summary-ratio), Figure \@ref(fig:Figure-ratio)). It is important to note that using all sectors or one sector within the same year requires some 12-hr sampling to be conducted within each year. The only set that requires no 12-hr sampling in the future is "Other years." Considering the logistical difficulties of conducting 12-hr sampling at all sectors, I compare overall hatchling estimates from "other sectors" and "other years" in the following section.  


```{r Table-summary-ratio, echo=FALSE, warning=FALSE}
flextable(ratio.summary.table) %>% 
  #hline(i = (nrow(ratio.summary.table)-1)) %>%
 set_caption(paste0("A comparison of data sets for cross validation to calculate the second half of a survey from the first half. Results in the table indicate the differences from the true values.")) %>%
  set_table_properties(width = 0.5, layout = "autofit") %>%
  colformat_double(j = c("Mean", "SD", "min", "max"), digits = 2)

```


### Estimating the unobserved counts from ratios

In this section, I use the entire dataset and estimate the number of hatchlings for the second half of each evening when no survey was conducted from 2400 - 0600, using all available ratios from all years and all sectors.  

```{r proportion-estimates, echo=FALSE, message=FALSE, warning=FALSE}

# Similar to the cross validation above but with missing data
# Add the counts for each night with 6-hr sampling
data.1 %>% 
  filter(survey_duration_hr < 12) %>%
  select(sector, year, date, counts, trench_length_m, date_num, counts, counts_m) %>%
  group_by(sector, year, date) %>%
  summarize(across(.cols = counts, 
                     .fns = sum, 
                     na.rm = T, 
                     .names = "counts_1"),
              length = first(trench_length_m),
              date_num = first(date_num)) %>%
  mutate(counts_m_1 = counts_1/length) %>%
  transmute(sector = sector,
            year = year,
            date = date,
            counts_1 = counts_1,
            length = length,
            date_num = date_num,
            counts_m_1 = counts_m_1,
            counts_2 = NA,
            counts_m_2 = NA,
            ratio = NA) -> counts.1st.2nd.6hr

# Combine them with the 12-hr sampling data
counts.1st.2nd.all <- rbind(counts.1st.2nd.12hr, counts.1st.2nd.6hr)

# Create a sequential ID number for each survey 
date_num_df <- data.frame(date_num = unique(counts.1st.2nd.all$date_num),
                          date_seq = 1:length(unique(counts.1st.2nd.all$date_num)))

# Add the sequential ID numbers to the data frame
counts.1st.2nd.all %>%
  left_join(date_num_df, by = "date_num") -> counts.1st.2nd.all

# Create the output data frame with extra columns for estimates
data.out <- counts.1st.2nd.all

# find how many are missing:
n.missing <- counts.1st.2nd.all %>% 
  filter(is.na(counts_2)) %>% 
  nrow()

n.notNA <- counts.1st.2nd.all %>%
  filter(!is.na(counts_2)) %>%
  nrow()

# Mean proportion using all that are available
mean.prop <- 1 - mean(counts.1st.2nd.all$ratio, na.rm = T)
var.prop <- var(1 - counts.1st.2nd.all$ratio, na.rm = T)

# To get uncertainty in the proportion, I fit the beta distribution:
beta.fit <- beta.params(mean.prop, var.prop)
qtiles.fit <- qbeta(c(0.025, 0.5, 0.975), 
                    beta.fit$alpha, 
                    beta.fit$beta)

# Visual check to see if the estimates are okay:
# beta.density <- data.frame(x = seq(0, 1, by = 0.01),
#                            density = dbeta(seq(0, 1, by = 0.01), 
#                                            beta.fit$alpha, 
#                                            beta.fit$beta))
# 
# ggplot(data = counts.1st.2nd.all) +
#   geom_histogram(aes(x = 1 - ratio, y = ..density..),
#                  binwidth = 0.1) +
#   geom_density(aes(x = 1 - ratio),
#                color = "blue", size = 1) +
#   geom_path(data = beta.density,
#             aes(x = x, y = density),
#             color = "red",
#             size = 1)

# Looks alright. 


data.out$estim.2 <- data.out$counts_1 * mean.prop
data.out$q2.5 <- data.out$counts_1 * qtiles.fit[1]
data.out$q50 <- data.out$counts_1 * qtiles.fit[2]
data.out$q97.5 <- data.out$counts_1 * qtiles.fit[3]

p.estimated.prop <- ggplot(data = data.out) + 
  geom_point(aes(x = counts_1, 
                 y = estim.2, 
                 color = sector),
                 #size = duration_hr),
             alpha = 0.3) +
  geom_errorbar(aes(x = counts_1,
                    ymin = q2.5,
                    ymax = q97.5,
                    color = sector),
                alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0)+
  facet_wrap(~ year) + labs(title = "Ratio") +
  xlab("Counts from 1800-2400") +
  ylab("Estimated counts from 2400-0600")

save.fig.fcn(p.estimated.prop, 
             file.name = paste0("figures/estimated_counts2_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)


```





### Statistical modeling of hatchling counts {-}

In this section, I use a statistical model to estimate the number of hatchlings during the second half of the night from the first half. I treated the observed number of hatchlings from 1800 to 2400 (n) in the j-th sector of the k-th sampling day during the y-th year as a Poisson random deviate. Sampling distance (L) jwas changed from 100 m to 50 m. Consequently, the sampling length needs to be accounted for in the model. When taking the natural log of the counts per distance, 

$ ln(n/L) = ln(n) - ln(L) $.

We assume that we can model the relationship $ln(n/L)$ with a function, say $f(...)$, where $\dots$ indicate one or more parameters. 

$$
\begin{aligned}
ln(n) - ln(L) &= f(...) \\
 ln(n) &= f(...) + ln(L) \\
 n &= L \exp(f(...)) 
\end{aligned} 
$$

First, I considered the Poisson distribution as the likelihood function for the observed counts ($n$ and $m$). However, it did not fit well according to the Pareto k statistics, which measure how well a statistical model fit to the observed data in the Bayesian context (ref here). Consequently, I altered the likelihood function to the normal distribution and transformed the observed counts in the natural log scale. In order to deal with zero counts, I added one to each count.

$ ln(n_{j, k, y} + 1) \sim N(\lambda_{j, k, y}, \sigma_n)$,

where $\sigma_n$ is the standard deviation. 

The number of hatchlings from 2400 to 0600 (m) (plus one) in the natural log space is also a normal random deviate and its mean is a function of $\lambda_{j,k,y}$ and the proportion of the number of hatchlings from 1800 to 2400 to that from 1800 to 2400 ($\theta_{j,k,y}$):

$ ln(m_{j,k,y} +1) \sim N(\lambda_{j,k,y} + \theta_{j,k,y}, \sigma_m) $.

The mean ($\lambda_{j, k, y}$) is a function of covariates, including year (Y) and the number of females ($N_{female}$), the day of sampling (# days since Jan 1; $D_{j,k,y}$), and sector ($S_{j,y}$):

$\lambda_{j,k,y} = ln(L_{j,k,y}) + S_{j,y} + \beta_1 Y + \beta_2 N_{y} + \beta_3 D_{j,k,y} $,

Effects of covariates on the mean ($\lambda$) were investigated by developing a series of models with different sets of covariates for the mean. In total, I developed six models:

1. $\lambda_{j,k,y} = ln(L_{j,k,y}) + S_{j} + \beta_1 Y + \beta_2 N_{y} + \beta_3 D_{j,k,y} $

2. $\lambda_{j,k,y} = ln(L_{j,k,y}) + S_{j} + \beta_2 N_{y} + \beta_3 D_{j,k,y}$

3. $\lambda_{j,k,y} = ln(L_{j,k,y}) + S_{j}$

4. $\lambda_{j,k,y} = ln(L_{j,k,y}) + \beta_2 N_{y} + \beta_3 D_{j,k,y} $

5. $\lambda_{j,k,y} = ln(L_{j,k,y}) + \beta_0 + \beta_2 N_{y} + \beta_3 D_{j,k,y}$

6.  $\lambda_{j,k,y} = ln(L_{j,k,y}) + S_{j} + \beta_2 N_{y}$

For the additive term ($\theta$), in the log scale, that converts the mean for the first half of the evening ($\lambda$) to the second half of the evening ($\lambda + \theta$), I looked at five variations:

1. year specific ($\theta_{y}$)

2. year and sector specific ($\theta_{j, y}$)

3. sector specific ($\theta){j}$)

4. year, sector, and sampling day specific ($\theta{j,k,y}$)

5. Constant ($\theta$)

A total of 30 models were created. The naming convention was the $\theta$ model first as the main version (v1 - v5), followed by $\lambda$ definitions (e.g., v1-1, v1-2, etc.). For all versions with year index (i.e., v1, v2, and v4), some 12-hr sampling is necessary to estimate the appropriate $\theta$ for each year. For v3, data from previous years can be used for sector-specific $\theta$. For v5, all available data are combined to estimate $\theta$.

I used the following prior distributions.

$ \lambda_{j,k,y} \sim GAM(0.1, 0.01)$

$ \theta_{j,k,y} \sim UNIF(-10, 10)$

The density functions for these prior distributions are shown in Figure X. 

To test the modeling approach, I first used only data with 12-hr sampling and conducted cross-validations by withholding one 2400-0600 period at a time. 


```{r modeling-1, echo=FALSE, message=FALSE}
library("jagsUI")
library("bayesplot")

MCMC.params <- list(n.chains = 5,
                    n.samples = 100000,
                    n.burnin = 80000,
                    n.thin = 5)


# Calculate number of days since Jan 1 of each year
 counts.1st.2nd %>% 
   mutate(n.days = 11 + as.numeric(ymd(date) - ymd(paste0(year, "-01-01")))) -> counts.1st.2nd
  
# 
date_num_df <- data.frame(date_num = unique(counts.1st.2nd$date_num),
                           date_seq = 1:length(unique(counts.1st.2nd$date_num)))

# numeric sectors
sector_num_df <- data.frame(sector = unique(counts.1st.2nd$sector),
                            sector_num = 1:length(unique(counts.1st.2nd$sector)))

years.df <- data.frame(year = unique(counts.1st.2nd$year)) %>%
    left_join(n.females.df, by = "year") 

counts.1st.2nd %>%
  left_join(date_num_df, by = "date_num") %>%
  left_join(sector_num_df, by = "sector") %>%
  select(-c(date, date_num)) %>%
  mutate(year_num = year - min(data.1$year) + 1) %>%
  group_by(year_num, sector_num) %>%
  mutate(seq_date = row_number()) %>%
  left_join(years.df, by = "year") -> counts.1st.2nd.jags.data

jags.params <- c("lambda", "p", "lambda.k",
                 "S", "mu.S", "sigma.S",
                 "B.N.fem", "B.day", "B0",
                 "sigma.n", "sigma.m",
                 "deviance", "loglik.n", "loglik.m")

# for Poisson likelihood
# jags.data <- list(n = counts.1st.2nd.jags.data$counts_1,
#                   m = counts.1st.2nd.jags.data$counts_2,
#                   length = counts.1st.2nd.jags.data$length,
#                   day = counts.1st.2nd.jags.data$n.days,
#                   sector = counts.1st.2nd.jags.data$sector_num,
#                   n.years = length(unique(counts.1st.2nd.jags.data$year_num)),
#                   n.sectors = length(unique(counts.1st.2nd.jags.data$sector_num)),
#                   N.fem = counts.1st.2nd.jags.data$n.females,
#                   year = counts.1st.2nd.jags.data$year_num,
#                   seq_date = counts.1st.2nd.jags.data$seq_date,
#                   max.seq_date = max(counts.1st.2nd.jags.data$seq_date, na.rm = T),
#                   n.data = nrow(counts.1st.2nd.jags.data))

# for log normal likelihood
jags.data <- list(n = log(counts.1st.2nd.jags.data$counts_1 + 1),
                  m = log(counts.1st.2nd.jags.data$counts_2 + 1),
                  length = counts.1st.2nd.jags.data$length,
                  day = counts.1st.2nd.jags.data$n.days,
                  sector = counts.1st.2nd.jags.data$sector_num,
                  n.years = length(unique(counts.1st.2nd.jags.data$year_num)),
                  n.sectors = length(unique(counts.1st.2nd.jags.data$sector_num)),
                  N.fem = counts.1st.2nd.jags.data$n.females,
                  N.fem.year = as.vector(n.females.df$n.females),
                  year = counts.1st.2nd.jags.data$year_num,
                  seq_date = counts.1st.2nd.jags.data$seq_date,
                  max.seq_date = max(counts.1st.2nd.jags.data$seq_date, na.rm = T),
                  n.data = nrow(counts.1st.2nd.jags.data),
                  gamma.alpha = 1,
                  gamma.beta = 0.1,
                  max.p = 10,
                  min.p = -10)

# vk-1 is with # days since Jan 1, # females, and Sector random effects
# vk-2 is without # days but with # females, and sector random effects
# vk-3 is no # days and no # females and just sector random effects
# vk-4 has no sector effects. Just # females and # days.

# v1 has year specific proportions (p[year])
#out.file.name <- "RData/jags_out_hatchling_counts.rds"
out.file.name <- "RData/jags_out_hatchling_log_counts.rds"
model.base.name <- "models/model_log_counts_estimation_"

if (!file.exists(out.file.name)){
  model.names <- c("v1-1", "v1-2", "v1-3", "v1-4", "v1-5", "v1-6",
                   "v2-1", "v2-2", "v2-3", "v2-4", "v2-5", "v2-6",
                   "v3-1", "v3-2", "v3-3", "v3-4", "v3-5", "v3-6",
                   "v4-1", "v4-2", "v4-3", "v4-4", "v4-5", "v4-6",
                   "v5-1", "v5-2", "v5-3", "v5-4", "v5-5", "v5-6")
  
  jags.out <- LOOIC.out.n <- LOOIC.out.m <- list()
  start.time <- now()
  
  k <- 1
  for (k in 1:length(model.names)){
    print(paste("Model ", k, " of ", length(model.names)))
    #model.file <- paste0("models/model_counts_estimation_", model.names[k], ".txt")
    model.file <- paste0(model.base.name, model.names[k], ".txt")
    jags.out[[k]] <- jags(jags.data,
                          inits = NULL,
                          parameters.to.save= jags.params,
                          model.file = model.file,
                          n.chains = MCMC.params$n.chains,
                          n.burnin = MCMC.params$n.burnin,
                          n.thin = MCMC.params$n.thin,
                          n.iter = MCMC.params$n.samples,
                          DIC = T, parallel=T)
    
    LOOIC.out.n[[k]] <- compute.LOOIC(loglik.mat = jags.out[[k]]$sims.list$loglik.n,
                                      data.vector = jags.data$n,
                                      MCMC.params = MCMC.params)
    
    LOOIC.out.m[[k]] <- compute.LOOIC(loglik.mat = jags.out[[k]]$sims.list$loglik.m,
                                      data.vector = jags.data$n,
                                      MCMC.params = MCMC.params)
  }

  end.time <- now()
  
  out.list <- list(model.names = model.names,
                   jm.out = jags.out,
                   LOOIC.out.m = LOOIC.out.m,
                   LOOIC.out.n = LOOIC.out.n,
                   jags.data = jags.data,
                   jags.params = jags.params,
                   MCMC.params = MCMC.params,
                   run.date = Sys.Date(),
                   system = Sys.info(),
                   run.time = end.time - start.time)
  
  saveRDS(out.list, file = out.file.name)
} else {
  #out.list <- readRDS("RData/jags_out_hatchling_counts.rds")
  out.list <- readRDS(out.file.name)
}

LOOIC.df <- data.frame(model = out.list$model.names,
                     DIC = lapply(out.list$jm.out, 
                                  FUN = function(x) x$DIC) %>% unlist(),
                     Rhat = lapply(out.list$jm.out, 
                                   FUN = function(x) x$Rhat %>% unlist() %>% 
                                     max(na.rm = T)) %>% unlist(),
                     LOOIC.m = lapply(out.list$LOOIC.out.m, 
                                      FUN = function(x) x$loo.out$estimates["looic", "Estimate"]) %>% 
                       unlist(),
                     max.pareto.m = lapply(out.list$LOOIC.out.m, 
                                           FUN = function(x) x$loo.out$diagnostics$pareto_k %>% max()) %>%
                       unlist(),
                     LOOIC.n = lapply(out.list$LOOIC.out.n, 
                                      FUN = function(x) x$loo.out$estimates["looic", "Estimate"]) %>% unlist(),
                                          max.pareto.n = lapply(out.list$LOOIC.out.n, 
                                           FUN = function(x) x$loo.out$diagnostics$pareto_k %>% max()) %>%
                       unlist()) %>%
  mutate(dDIC = DIC - min(DIC),
         dLOOIC.m = LOOIC.m - min(LOOIC.m),
         dLOOIC.n = LOOIC.n - min(LOOIC.n)) %>%
  select(-c("DIC", "LOOIC.m", "LOOIC.n")) %>%
  arrange(dLOOIC.m) %>% 
  select(model, Rhat, dDIC, dLOOIC.m, dLOOIC.n, max.pareto.m, max.pareto.n)
  

```


Almost all models converged fine according to Rhat values (Table \@ref(tab:Table-model-summary)). According to DIC values, the best model was `r LOOIC.df %>% filter(dDIC == 0) %>% select(model) %>% pull()`, which also was the best model according to LOOIC values for m. Pareto k statistics indicated that the model fit well to the data. This model treats the additive factor to be year-specific  ($\theata_{y}$) and common among sectors. The mean number of hatchlings before the midnight is a function of sector, the number of days since January 1st, and the number of estimated females for the year. The first 12 models were v1 and v2, indicating that the additive factor is likelyl to be year specific (v1: year specific, v2: year and sector specific). The first v5 (constant $\theta$) model was v5-4. I will investigate the performance of v1-1 and v5-4 for their predictive performance in the following. 


```{r Table-model-summary, echo=FALSE, warning=FALSE}
flextable(LOOIC.df) %>% 
  #hline(i = (nrow(ratio.summary.table)-1)) %>%
 set_caption(paste0("Model comparison.")) %>%
  set_table_properties(width = 0.5, layout = "autofit") %>%
  colformat_double(j = c("Rhat", "dDIC", "dLOOIC.m", "dLOOIC.n", "max.pareto.m", "max.pareto.n"), digits = 2)

```

Although Rhat values seem to indicate MCMC converged fine, I also use visual aid to check good mixing of Markov chains. 


```{r p-trace-plots, echo=FALSE, message=FALSE}
model.ver <- "v5-1"
jm <- out.list$jm.out[[which(out.list$model.names == model.ver)]]

switch(str_split(model.ver, "-", simplify = TRUE)[1],
       v1 = mcmc_trace(jm$samples, c("p[1]", "p[2]", "p[3]", "p[4]")),
       v2 = mcmc_trace(jm$samples, c("p[1,1]", "p[2,1]", "p[3,1]",
                                     "p[4,1]", "p[1,2]", "p[2,2]", "p[3,2]",
                                     "p[4,2]")),
       v3 = mcmc_trace(jm$samples, c("p[1]", "p[2]", "p[3]",
                                     "p[4]", "p[5]")),
       v4 = mcmc_trace(jm$samples, c("p[1,1,1]", "p[1,1,2]", "p[1,1,3]",
                                     "p[1,1,4]", "p[1,1,5]", "p[1,1,6]",
                                     "p[1,1,7]", "p[2,1,1]", "p[2,1,2]")),
       v5 =   mcmc_trace(jm$samples, c("p"))
)



```


```{r S-trace-plots, echo=FALSE, message=FALSE}
# some models don't have S's
v <- str_split(model.ver, "-", simplify = TRUE)[2]

if (v != "4" | v != "5")
  mcmc_trace(jm$samples, c("S[1]", "S[2]", "S[3]", "S[4]", "S[5]"))


```


```{r muS-sS-trace-plots, echo=FALSE, message=FALSE}

mcmc_trace(jm$samples, c("mu.S", "sigma.S"))


```


```{r sigma.n-B.N.fem-trace-plots, echo=FALSE, message=FALSE}

switch(str_split(model.ver, "-", simplify = TRUE)[2],
       "3" = mcmc_trace(jm$samples, c("sigma.n", "sigma.m")),
       "1" = mcmc_trace(jm$samples, c("sigma.n", "sigma.m", "B.N.fem")),
       "2" = mcmc_trace(jm$samples, c("sigma.n", "sigma.m", "B.N.fem")),
       "4" = mcmc_trace(jm$samples, c("sigma.n", "sigma.m", "B.N.fem")),
       "6" = mcmc_trace(jm$samples, c("sigma.n", "sigma.m", "B.N.fem")))


```


The model is appeared to be working. Next step is to do cross validation and estimate one m at a time. 

```{r X-validation-1, echo=FALSE, message=FALSE}

cross.validation.v1_1.out <- cross.validataion.fcn(model.base.name = model.base.name, 
                                                   model.ver = "v1-1", 
                                                   jags.data = jags.data, 
                                                   jags.params = jags.params, 
                                                   MCMC.params = MCMC.params, 
                                                   original.data = counts.1st.2nd.jags.data)

cross.validation.v5_1.out <- cross.validataion.fcn(model.base.name = model.base.name, 
                                                   model.ver = "v5-1", 
                                                   jags.data = jags.data, 
                                                   jags.params = jags.params, 
                                                   MCMC.params = MCMC.params, 
                                                   original.data = counts.1st.2nd.jags.data)

model.ver <- "v5-1"
p.X_validation <- ggplot(cross.validation.v5_1.out$output) +
  #geom_point(aes(x = sector, y = counts_2),
  #           color = "gold") +
  geom_point(aes(x = log(counts_2+1), 
                 y = estim.m, 
                 color = sector)) +
  geom_errorbar(aes(x = log(counts_2 + 1),
                    ymin = q2.5.m,
                    ymax = q97.5.m,
                    color = sector)) +
  geom_abline(slope = 1, intercept = 0)+
  facet_wrap(~ year) +
  xlab("log(observed + 1)") + ylab("log(Estimated + 1)") +
  labs(title = model.ver)

save.fig.fcn(p.X_validation, 
             file.name = paste0("figures/Cross_validation_log_", model.ver, "_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)

```

The cross validation process indicated that the model predicted missing values fairly well (Figure \@ref(fig:Figure-X-validation-log-v1-1)), where observed and estimated values nearly lined up on the y = x line. Deviation from the line, however, was obvious for 2017 and 2018. It is important to note that v1-1 model has a year-specific $\theta$ values, which require more than one 12-hr sampling needs to be conducted annually in order for this model to work. 


```{r Figure-X-validation-log-v1-1, echo=FALSE, message=FALSE, fig.cap="The differences between the observed and calculated numbers of hatchlings using a statistical model (v1-1). Calculations were conducted in a cross validation manner where each survey was withheld from computing the ratio to be used in calculating the second half of the evening."}

knitr::include_graphics(paste0("figures/Cross_validation_log_v1-1_", dpi.set, "dpi.png"))

```


The best model with a common $\theta$ value was V5-1 (Table \@ref(tab:Table-model-summary)). The model fit well to the data according to the Pareto-k statistics, although it was ranked in the middle of the pack. I also examined the predicted and true values from the model using the same cross validation technique. Results indicated that the model seems to adequately estimated the missing value (Figure \@ref(fig:Figure-x-validation-log_v5-1)).


```{r Figure-X-validation-log-v5-1, echo=FALSE, message=FALSE, fig.cap="The differences between the observed and calculated numbers of hatchlings using a statistical model (v5-1). Calculations were conducted in a cross validation manner where each survey was withheld from computing the ratio to be used in calculating the second half of the evening."}

knitr::include_graphics(paste0("figures/Cross_validation_log_v5-1_", dpi.set, "dpi.png"))

```


## EStimating unobserved counts {-}

I applied these models (v1-1 and v5-1) to the entire data set in order to estimate the counts from 2400 - 0600, when no surveys were conducted. 

```{r estimating-missing-counts, echo=FALSE, message=FALSE}

counts.all <- summarize.counts(data.1)

# Calculate number of days since Jan 1 of each year
counts.all %>% 
  mutate(n.days = 11 + as.numeric(ymd(date) - ymd(paste0(year, "-01-01")))) -> counts.all
  
date_num_df <- data.frame(date_num = unique(counts.all$date_num),
                          date_seq = 1:length(unique(counts.all$date_num)))

# numeric sectors
sector_num_df <- data.frame(sector = unique(counts.all$sector),
                            sector_num = 1:length(unique(counts.all$sector)))

years.df <- data.frame(year = unique(counts.all$year)) %>%
    left_join(n.females.df, by = "year") 

counts.all %>%
  left_join(date_num_df, by = "date_num") %>%
  left_join(sector_num_df, by = "sector") %>%
  select(-c(date, date_num)) %>%
  mutate(year_num = year - min(data.1$year) + 1) %>%
  group_by(year_num, sector_num) %>%
  mutate(seq_date = row_number()) %>%
  left_join(years.df, by = "year") -> counts.all.jags.data

jags.params <- c("lambda", "p", "lambda.k",
                 "S", "mu.S", "sigma.S",
                 "B.N.fem", "B.day", "B0",
                 "sigma.n", "sigma.m",
                 "deviance", "loglik.n", "loglik.m")

# for log normal likelihood
jags.data <- list(n = log(counts.all.jags.data$counts_1 + 1),
                  m = log(counts.all.jags.data$counts_2a + 1),
                  length = counts.all.jags.data$length_m,
                  day = counts.all.jags.data$n.days,
                  sector = counts.all.jags.data$sector_num,
                  n.years = length(unique(counts.all.jags.data$year_num)),
                  n.sectors = length(unique(counts.all.jags.data$sector_num)),
                  N.fem = counts.all.jags.data$n.females,
                  N.fem.year = as.vector(n.females.df$n.females),
                  year = counts.all.jags.data$year_num,
                  seq_date = counts.all.jags.data$seq_date,
                  max.seq_date = max(counts.all.jags.data$seq_date, na.rm = T),
                  n.data = nrow(counts.all.jags.data),
                  gamma.alpha = 1,
                  gamma.beta = 0.1,
                  max.p = 10,
                  min.p = -10)
 
model.names <- c("v1-1", 
                 "v5-1")

m.estims <- jags.out <- LOOIC.out.n <- LOOIC.out.m <- list()

start.time <- now()
k <- 1
for (k in 1:length(model.names)){
  
  print(paste("Model ", k, " of ", length(model.names)))
  #model.file <- paste0("models/model_counts_estimation_", model.names[k], ".txt")
  model.file <- paste0(model.base.name, model.names[k], ".txt")
  jags.out[[k]] <- jags(jags.data,
                        inits = NULL,
                        parameters.to.save= jags.params,
                        model.file = model.file,
                        n.chains = MCMC.params$n.chains,
                        n.burnin = MCMC.params$n.burnin,
                        n.thin = MCMC.params$n.thin,
                        n.iter = MCMC.params$n.samples,
                        DIC = T, parallel=T)
  
   # calculate m[k] using the posterior samples 
  model.ver <- model.names[k]
  m.estim <- m.q2.5 <- m.q50 <- m.q97.5 <- vector(mode = "numeric", length = length(jags.data$m))
  for (k1 in 1:length(jags.data$m)){
    m.k <- jags.data$m[k1]
    if (is.na(m.k)){
      if (str_split(model.ver, "-", simplify = TRUE)[1] == "v5"){
        p.samples <-  extract.samples("p",
                                      jags.out[[k]]$samples) 
      } else {
        p.samples <-  extract.samples(paste0("p[", jags.data$year[k], "]"),
                                      jags.out[[k]]$samples)
        
      }
      m.k <- jags.data$n[k1] + p.samples
      qtiles.m <- quantile(m.k, c(0.025, 0.5, 0.975))

      m.estim[k1] <- mean(m.k)
      m.q2.5[k1] <- qtiles.m[1]
      m.q50[k1] <- qtiles.m[2]
      m.q97.5[k1] <-qtiles.m[3]
      
    } else {
      m.estim[k1] <- jags.data$m[k1]
      m.q2.5[k1] <- jags.data$m[k1]
      m.q50[k1] <- jags.data$m[k1]
      m.q97.5[k1] <- jags.data$m[k1]
      
    }
    
  }
  
  m.estims[[k]] <- data.frame(m.estim = m.estim,
                              m.q2.5 = m.q2.5,
                              m.q50 = m.q50,
                              m.q97.5 = m.q97.5)
  
  LOOIC.out.n[[k]] <- compute.LOOIC(loglik.mat = jags.out[[k]]$sims.list$loglik.n,
                                    data.vector = jags.data$n,
                                    MCMC.params = MCMC.params)
  
  LOOIC.out.m[[k]] <- compute.LOOIC(loglik.mat = jags.out[[k]]$sims.list$loglik.m,
                                    data.vector = jags.data$n,
                                    MCMC.params = MCMC.params)
}

end.time <- now()

out.list <- list(model.names = model.names,
                 jm.out = jags.out,
                 LOOIC.out.m = LOOIC.out.m,
                 LOOIC.out.n = LOOIC.out.n,
                 m.estims = m.estims,
                 jags.data = jags.data,
                 jags.params = jags.params,
                 MCMC.params = MCMC.params,
                 run.date = Sys.Date(),
                 system = Sys.info(),
                 run.time = end.time - start.time)

LOOIC.df <- data.frame(model = out.list$model.names,
                       DIC = lapply(out.list$jm.out, 
                                    FUN = function(x) x$DIC) %>% unlist(),
                       Rhat = lapply(out.list$jm.out, 
                                     FUN = function(x) x$Rhat %>% unlist() %>% 
                                       max(na.rm = T)) %>% unlist(),
                       LOOIC.m = lapply(out.list$LOOIC.out.m, 
                                        FUN = function(x) x$loo.out$estimates["looic", "Estimate"]) %>% 
                         unlist(),
                       max.pareto.m = lapply(out.list$LOOIC.out.m, 
                                             FUN = function(x) x$loo.out$diagnostics$pareto_k %>%
                                               max()) %>%
                         unlist(),
                       LOOIC.n = lapply(out.list$LOOIC.out.n, 
                                        FUN = function(x) x$loo.out$estimates["looic", "Estimate"]) %>%
                         unlist(),
                       max.pareto.n = lapply(out.list$LOOIC.out.n, 
                                             FUN = function(x) x$loo.out$diagnostics$pareto_k %>%
                                               max()) %>%
                         unlist()) %>%
  mutate(dDIC = DIC - min(DIC),
         dLOOIC.m = LOOIC.m - min(LOOIC.m),
         dLOOIC.n = LOOIC.n - min(LOOIC.n)) %>%
  select(-c("DIC", "LOOIC.m", "LOOIC.n")) %>%
  arrange(dLOOIC.m) %>% 
  select(model, Rhat, dDIC, dLOOIC.m, dLOOIC.n, max.pareto.m, max.pareto.n)
```


Look at what happened with estimated counts.

```{r estimated-m, echo=FALSE, message=FALSE}

counts.all.estims <- cbind(counts.all, 
                           data.frame(estim_m_v1.1 = out.list$m.estims[[1]]$m.estim,
                                      q2.5_m_v1.1 = out.list$m.estims[[1]]$m.q2.5,
                                      q50_m_v1.1 = out.list$m.estims[[1]]$m.q50,
                                      q97.5_m_v1.1 = out.list$m.estims[[1]]$m.q97.5,
                                      estim_m_v5.1 = out.list$m.estims[[2]]$m.estim,
                                      q2.5_m_v5.1 = out.list$m.estims[[2]]$m.q2.5,
                                      q50_m_v5.1 = out.list$m.estims[[2]]$m.q50,
                                      q97.5_m_v5.1 = out.list$m.estims[[2]]$m.q97.5)) 

p.estimated.m <- ggplot(data = counts.all.estims) + 
  geom_point(aes(x = counts_1, 
                 y = exp(estim_m_v5.1)-1, 
                 color = sector),
                 #size = duration_hr),
             alpha = 0.3) +
  geom_errorbar(aes(x = counts_1,
                    ymin = exp(q2.5_m_v5.1),
                    ymax = exp(q97.5_m_v5.1),
                    color = sector),
                alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0)+
  facet_wrap(~ year) + labs(title = "v5-1") +
  xlab("Counts from 1800-2400") +
  ylab("Estimated counts from 2400-0600")

save.fig.fcn(p.estimated.m, 
             file.name = paste0("figures/estimated_m_v5-1_", dpi.set, "dpi.png"), 
             replace = F, dpi = dpi.set)

```

When estimating the second half of the evening from the hatchling counts of first half and data from other years, the variability is considerably less than if the counts were made during the second half of the evening (Figure \@ref(fig:Figure-estimated-counts-v5-1). 



```{r Figure-estimated-counts-v5-1, echo=FALSE, message=FALSE, fig.cap="Observed and estimated counts from 2400 - 0600 using the v5-1 model as a function of the counts from the first half of the evening. Data points without error bars are observed counts. The solid lines indicate y=x."}

knitr::include_graphics(paste0("figures/estimated_m_v5-1_", dpi.set, "dpi.png"))

```

## Comparing the ratio-based and model-based estimates 

The model-based estimation process requires a considerate effort. Computing ratios is a lot simpler and more efficient. Here, I compare the two methods and discuss pros and cons of two approaches. 



